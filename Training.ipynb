{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCO1TDYuuCgO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset as Dataset\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import time\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models, utils"
      ],
      "metadata": {
        "id": "SYidxEufkACl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/206/Bali Leaf Project/data/train'\n",
        "val_path = '/content/drive/MyDrive/206/Bali Leaf Project/data/val'\n",
        "test_path = '/content/drive/MyDrive/206/Bali Leaf Project/data/test'"
      ],
      "metadata": {
        "id": "Rg_ow2xRPEPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_transformations = transforms.Compose([\n",
        "    transforms.Resize(320),\n",
        "    transforms.CenterCrop(300),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.3),\n",
        "    transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.RandomRotation(degrees=(-90, 90)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Resize(320),\n",
        "    transforms.CenterCrop(300),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "LoDUONDoOXQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets.ImageFolder(train_path, transform = train_transformations)\n",
        "val_set = datasets.ImageFolder(val_path, transform = transformations)\n",
        "test_set = datasets.ImageFolder(test_path, transform = transformations)"
      ],
      "metadata": {
        "id": "FK3ekt-WOxip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_set))\n",
        "print(len(val_set))\n",
        "print(len(test_set))"
      ],
      "metadata": {
        "id": "34-Sv7jModFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "U7Ert2UJPOdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    print('img size: ', img.shape)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(utils.make_grid(images))\n",
        "# print labels\n",
        "# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "8NjSRYpsN7pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "num_labels = 26\n",
        "\n",
        "classifier = nn.Linear(512, num_labels)\n",
        "\n",
        "model.fc = classifier"
      ],
      "metadata": {
        "id": "sxbOpIzCPkwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "aP_le0JZaKuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "def train_model(model, loss_fn, optimizer, train_loader, val_loader, batch_size, num_epochs, stat_count=100, device=None):\n",
        "    print('Training...')\n",
        "    model.to(device)\n",
        "    min_valid_acc = 0\n",
        "    # Iterate through all Epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "\n",
        "        # Iterate through training dataset\n",
        "        model.train()\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # Flatten images and load images/labels onto GPU\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            # Zero collected gradients at each step\n",
        "            optimizer.zero_grad()\n",
        "            # Forward Propagate\n",
        "            outputs = model(images)\n",
        "            # Calculate Loss\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # Back Propagate\n",
        "            loss.backward()\n",
        "            # Update Weights\n",
        "            optimizer.step()\n",
        "            # Get Running Loss\n",
        "            train_loss += loss.item()\n",
        "            # Print statistics on every stat_count iteration\n",
        "            if (i+1) % stat_count == 0:\n",
        "                print('\\tEpoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                            %(epoch+1, num_epochs, i+1,\n",
        "                            len(train_loader), train_loss / i))\n",
        "\n",
        "        # val dataset\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "          for inputs, labels in val_loader:\n",
        "            images, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            val_loss += loss.item() #* images.size(0)\n",
        "\n",
        "        # Print stats\n",
        "        ep_train_loss = train_loss / len(train_loader)\n",
        "        ep_val_loss = val_loss / len(val_loader)\n",
        "        ep_val_acc = test_accuracy(model, val_loader, device=device)\n",
        "        ep_train_acc = test_accuracy(model, train_loader, device=device)\n",
        "        print('Epoch [%d/%d], Train (Loss: %.4f, Acc: %.4f), Val (Loss: %.4f, Acc: %.4f), '\n",
        "                            %(epoch+1, num_epochs, ep_train_loss, ep_train_acc, ep_val_loss, ep_val_acc), end=\" | \")\n",
        "        \n",
        "        train_losses.append(ep_train_loss)\n",
        "        train_accuracies.append(ep_train_acc)\n",
        "        val_accuracies.append(ep_val_acc)\n",
        "        val_losses.append(ep_val_loss)\n",
        "\n",
        "def test_accuracy(model, test_loader, device=None):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for test_data in test_loader:\n",
        "            images, labels = test_data[0].cuda(), test_data[1].cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def plot_learning_curve(train_losses, train_accuracies, val_losses, val_accuracies, num_epochs):\n",
        "  iterations = range(0, num_epochs)\n",
        "  plt.figure()\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.plot(iterations, train_losses, 'r')\n",
        "  plt.plot(iterations, val_losses, 'b')\n",
        "  plt.title('Training Performance')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "\n",
        "  plt.subplot(2,1,2)\n",
        "  plt.plot(iterations, train_accuracies, 'r')\n",
        "  plt.plot(iterations, val_accuracies, 'b')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.savefig('LR_curve.png')"
      ],
      "metadata": {
        "id": "EbL6_YChQfXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
        "lr = 1e-3\n",
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "# lambda1 = lambda epoch: epoch / 10\n",
        "# scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)"
      ],
      "metadata": {
        "id": "CtdBwTYKQ-6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/206/Bali Leaf Project/checkpoint_model.pth'))\n",
        "train_model(model, criterion, optimizer, train_loader, val_loader, batch_size, num_epochs, stat_count=100, device=device)"
      ],
      "metadata": {
        "id": "6i3E1zYLVzQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best train weights\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/206/Bali Leaf Project/checkpoint_model.pth'))\n",
        "test_acc = test_accuracy(model, test_loader, device)\n",
        "print('\\nTest Accuracy: ', test_acc)"
      ],
      "metadata": {
        "id": "_rxefwfBIEen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}